{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b35f9ca1-80cd-4c8e-8659-4f9b060182bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current directory: C:\\Users\\moses\\Documents\\git\\surmise\\examples\\bayesian_vah\\emulation_and_calibration\n",
      "surmise directory: C:\\Users\\moses\\Documents\\git\\surmise\\src\\surmise\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "print(r'current directory: {}'.format(Path(os.curdir).absolute()))\n",
    "\n",
    "# verify the use of current surmise package\n",
    "import surmise\n",
    "print(r'surmise directory: {}'.format(surmise.__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d94ddbbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T14:13:16.968973Z",
     "start_time": "2025-07-04T14:13:14.042167Z"
    }
   },
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "import time\n",
    "from split_data import generate_split_data\n",
    "from surmise.emulation import emulator\n",
    "from plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78dcd98b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T14:13:34.691122Z",
     "start_time": "2025-07-04T14:13:34.170091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We drop these observables ['pT_fluct_[0 5]', 'pT_fluct_[ 5 10]', 'pT_fluct_[10 15]', 'pT_fluct_[15 20]', 'pT_fluct_[20 25]', 'pT_fluct_[25 30]', 'pT_fluct_[30 35]', 'pT_fluct_[35 40]', 'pT_fluct_[40 45]', 'pT_fluct_[45 50]', 'pT_fluct_[50 55]', 'pT_fluct_[55 60]']\n",
      "Designs that have more that 5 failure event rate \n",
      " [ 13.  14.  19.  23.  27.  31.  32.  43.  59.  71.  75.  91.  92.  93.\n",
      "  98. 123. 127. 129. 131. 142. 143. 146. 156. 160. 162. 168. 169. 170.\n",
      " 171. 174. 184. 186. 187. 190. 194. 195. 196. 198. 210. 217. 233. 236.\n",
      " 239. 243. 245. 248. 249. 260. 262. 266. 269. 277. 282. 283. 286. 291.\n",
      " 293. 299.]\n",
      "Designs that have more that 5 failure event rate \n",
      " [ 4.  6. 10. 27. 29. 35. 38. 39. 43. 44. 63. 65. 70. 73. 76. 84. 85. 87.\n",
      " 88.]\n",
      "Designs that have more that 5 failure event rate \n",
      " [10. 17. 18. 22. 27. 35. 41. 49. 58. 82. 88.]\n",
      "Designs that have more that 5 failure event rate \n",
      " [ 0.  3.  6. 16. 18. 20. 22. 26. 33. 35. 37. 41. 42. 48. 52. 68. 71. 82.\n",
      " 83. 88.]\n",
      "Designs that have more that 5 failure event rate \n",
      " [ 3.  4. 14. 17. 30. 31. 38. 47. 60. 62. 64. 66. 69. 72.]\n",
      "Designs that have more that 5 failure event rate \n",
      " [ 7. 12. 14. 16. 18. 19. 25.]\n",
      "Designs that have more that 5 failure event rate \n",
      " []\n",
      "Designs that have more that 5 failure event rate \n",
      " []\n",
      "Designs that have more that 5 failure event rate \n",
      " []\n",
      "(471, 123)\n",
      "(471, 123)\n",
      "(471, 15)\n",
      "(70, 123)\n",
      "(70, 123)\n",
      "(70, 15)\n",
      "Number of model inputs 15\n"
     ]
    }
   ],
   "source": [
    "seconds_st = time.time()\n",
    "\n",
    "# Note: Here we can create different funcs to split data into training and test\n",
    "drop_obs_group = ['fluct']\n",
    "drop_subset = [f'{oob}_{cen}' for og in drop_obs_group for oob in obs_groups[og] for cen in obs_cent_list['Pb-Pb-2760'][oob]]\n",
    "print(f'We drop these observables {drop_subset}')\n",
    "f_train, f_test, theta_train, theta_test, sd_train, sd_test, y, thetanames = generate_split_data(drop_list=drop_subset)\n",
    "print(f'Number of model inputs {theta_train.shape[1]}')\n",
    "\n",
    "x_np = np.arange(0, f_train.shape[1])[:, None]\n",
    "x_np = x_np.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19668b2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T14:13:36.517737Z",
     "start_time": "2025-07-04T14:13:36.511596Z"
    }
   },
   "outputs": [],
   "source": [
    "fcal = f_train\n",
    "thetacal = theta_train\n",
    "sdcal = sd_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa56bac1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T14:20:57.857100Z",
     "start_time": "2025-07-04T14:17:00.813718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the emulation data set (471, 15)\n",
      "training emulators\n",
      "PCSK considering  12 PCs\n",
      "\n",
      " interation number 0 : 0% 17.0 % 25.0 % 33.0 % 42.0 % 58.0 % 67.0 % "
     ]
    }
   ],
   "source": [
    "print(f'Shape of the emulation data set {thetacal.shape}')\n",
    "x_np = np.arange(0, fcal.shape[1])[:, None]\n",
    "x_np = x_np.astype('object')\n",
    "\n",
    "##########################################################\n",
    "# Note: Pick method_name = 'PCGPwM' or 'PCGPR' or 'PCSK'\n",
    "##########################################################\n",
    "\n",
    "method_name = 'PCSK'\n",
    "is_train = True\n",
    "emu_path = 'VAH_validate_' + method_name + '.pkl' \n",
    "        \n",
    "prior_min = [10, -0.7, 0.5, 0, 0.3, 0.135, 0.13, 0.01, -2, -1, 0.01, 0.12, 0.025, -0.8, 0.3]\n",
    "prior_max = [30, 0.7, 1.5, 1.7, 2, 0.165, 0.3, 0.2, 1, 2, 0.25, 0.3, 0.15, 0.8, 1]\n",
    "prior_dict = {'min': prior_min, 'max': prior_max}\n",
    "\n",
    "if (os.path.exists(emu_path)) and (is_train==False):\n",
    "    print('Saved emulators exists and overide is prohibited')\n",
    "    with open(emu_path, 'rb') as file:\n",
    "        emu_tr = pickle.load(file)    \n",
    "else:\n",
    "    print('training emulators')\n",
    "    if method_name == 'PCGPwM':\n",
    "        emu_tr = emulator(x=x_np,\n",
    "                          theta=thetacal,\n",
    "                          f=fcal.T,\n",
    "                          method='PCGPwM',\n",
    "                          args={'epsilon': 0.05})\n",
    "        \n",
    "    elif method_name == 'PCGPR':\n",
    "        emu_tr = emulator(x=x_np,\n",
    "                          theta=thetacal,\n",
    "                          f=fcal.T,\n",
    "                          method='PCGPR',\n",
    "                          args={'epsilon': 0.02,\n",
    "                                'prior': prior_dict})\n",
    "    elif method_name == 'PCSK':\n",
    "        #Scale pt_fluc uncertainity\n",
    "        #l_in=index['pT_fluct']\n",
    "        #print(l_in)\n",
    "        #sdcal[:,index['pT_fluct'][0]:-1] =  10* sdcal[:,index['pT_fluct'][0]:-1]\n",
    "        #sdcal = np.sqrt(np.absolute(sdcal))\n",
    "        emu_tr = emulator(x=x_np,\n",
    "                          theta=thetacal,\n",
    "                          f=fcal.T,\n",
    "                          method='PCSK',\n",
    "                          args={'numpcs': 12, # this does not mean full errors\n",
    "                                'simsd': np.absolute(sdcal.T),\n",
    "                                'verbose': 1})\n",
    "\n",
    "\n",
    "    # if (is_train==True) or not(os.path.exists(emu_path)):\n",
    "    #     with open(emu_path, 'wb') as file:\n",
    "    #         pickle.dump(emu_tr, file)\n",
    "\n",
    "\n",
    "seconds_end = time.time()\n",
    "print('Total emu time:', seconds_end - seconds_st)\n",
    "\n",
    "\n",
    "seconds_st = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d46abed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T14:21:27.646784Z",
     "start_time": "2025-07-04T14:21:26.760769Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_test = emu_tr.predict(x=x_np, theta=theta_test)\n",
    "pred_test_mean = pred_test.mean()\n",
    "pred_test_var = pred_test.var()\n",
    "pred_test_sigma = np.sqrt(pred_test_var)\n",
    "# Plotting diagnostics\n",
    "#plot_UQ(f_test, pred_test_mean.T, np.sqrt(pred_test_var.T), method=method_name, drop=drop_obs_group)\n",
    "plot_R2(pred_test_mean, f_test.T, method=method_name, drop=drop_obs_group)\n",
    "\n",
    "seconds_end = time.time()\n",
    "print('Total emu time:', seconds_end - seconds_st)\n",
    "\n",
    "\n",
    "seconds_st = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a5d75a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T14:21:30.135738Z",
     "start_time": "2025-07-04T14:21:30.131948Z"
    }
   },
   "outputs": [],
   "source": [
    "index={}\n",
    "st_index=0\n",
    "for obs_group in  obs_groups.keys():\n",
    "    if obs_group in drop_obs_group:\n",
    "        continue;\n",
    "    for obs in obs_groups[obs_group]:\n",
    "        n_centrality = len(obs_cent_list['Pb-Pb-2760'][obs])\n",
    "        index[obs]=[st_index,st_index+n_centrality]\n",
    "        st_index = st_index + n_centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954e0ae4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T14:21:33.631980Z",
     "start_time": "2025-07-04T14:21:33.627502Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f99f8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T14:21:39.196790Z",
     "start_time": "2025-07-04T14:21:35.859347Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_context('poster', font_scale=1.5)\n",
    "fig, axs = plt.subplots(4,3,figsize=(30,40))\n",
    "axs = axs.flatten()\n",
    "keep_ylabel = [0, 3, 6, 9]\n",
    "keep_ylabel = []\n",
    "for i, k in enumerate(index.keys()):\n",
    "    #print(k)\n",
    "    low = index[k][0]\n",
    "    high = index[k][1]\n",
    "    ax = axs[i]\n",
    "    emu_mean  = pred_test_mean[low:high,:].flatten()\n",
    "    emu_err  = pred_test_sigma[low:high,:].flatten()\n",
    "    sim_mean = f_test.T[low:high,:].flatten()\n",
    "    sim_err = sd_test.T[low:high,:].flatten()\n",
    "    ax.errorbar(emu_mean, sim_mean, fmt='+', xerr=emu_err, yerr=abs(sim_err), alpha = 0.4 )\n",
    "    ax.set_title(obs_tex_labels[k])\n",
    "    ax.plot(ax.get_xlim(), ax.get_xlim(), color='k')\n",
    "    ax.set_xlabel('Emulated')\n",
    "    ax.set_ylabel('Simulated')\n",
    "fig.delaxes(axs[-1])\n",
    "plt.tight_layout()\n",
    "plt.savefig('emulated_vs_simulated.png', dpi=100)\n",
    "    #print(y.columns[low:high])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2583ea087818c73f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
