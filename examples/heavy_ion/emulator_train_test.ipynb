{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.8\n",
      "numpy: 1.26.4\n",
      "pandas: 2.2.1\n",
      "scipy: 1.12.0\n",
      "scikit-learn: 1.5.1\n",
      "dill: 0.3.8\n",
      "joblib: 1.3.2\n",
      "psutil: 5.9.8\n",
      "pip: 24.0\n",
      "surmise: 0.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w7/ygz14_194fs1mqhvr0jwdcc80000gn/T/ipykernel_41677/3590732199.py:2: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pkg_resources\n",
    "\n",
    "# Get Python version\n",
    "python_version = sys.version.split(\" \")[0]\n",
    "\n",
    "# Define the packages\n",
    "packages = [\"numpy\", \"pandas\", \"scipy\", \"scikit-learn\", \"dill\", \"joblib\", \"psutil\", \"pip\", \"surmise\"]\n",
    "\n",
    "# Get package versions, skipping those that are not installed\n",
    "package_versions = {}\n",
    "for pkg in packages:\n",
    "    try:\n",
    "        package_versions[pkg] = pkg_resources.get_distribution(pkg).version\n",
    "    except pkg_resources.DistributionNotFound:\n",
    "        package_versions[pkg] = \"Not installed\"\n",
    "\n",
    "print(f\"Python version: {python_version}\")\n",
    "for pkg, version in package_versions.items():\n",
    "    print(f\"{pkg}: {version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emulator train and test : No k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in AKSGP emulator class called\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../../surmise/emulationmethods'))\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dill\n",
    "import gzip\n",
    "\n",
    "# import surmise\n",
    "from surmise.emulation import emulator\n",
    "from AKSGP import Emulator as emulator_AKSGP\n",
    "from PCGP_scikit import Emulator as PCGP_scikit\n",
    "\n",
    "import logging\n",
    "\n",
    "# Configure logging for the Emulator class\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', \n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# Load training data\n",
    "train_dir = 'simulation_data/Pb_Pb_2760_Grad/train'\n",
    "X = np.loadtxt(os.path.join(train_dir, 'X.txt'))\n",
    "Ymean = np.loadtxt(os.path.join(train_dir, 'Ymean.txt'))\n",
    "Ystd = np.loadtxt(os.path.join(train_dir, 'Ystd.txt'))\n",
    "\n",
    "# for quick tests\n",
    "numdesignpt = 100\n",
    "numobs = 4\n",
    "X = X[:numdesignpt, :]\n",
    "Ymean = Ymean[:numdesignpt,:numobs]\n",
    "Ystd = Ystd[:numdesignpt,:numobs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and save emulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xloc = np.arange(Ymean.shape[1])  # refers to the observable indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 14:17:41 - __main__ - INFO - Emulator 'PCGP' trained and saved.\n",
      "\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 6 of parameter k1__k2__length_scale is close to the specified upper bound 54.252. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 7 of parameter k1__k2__length_scale is close to the specified upper bound 13.710999999999999. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 15 of parameter k1__k2__length_scale is close to the specified upper bound 549.137. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 16 of parameter k1__k2__length_scale is close to the specified upper bound 2.8340000000000005. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 0.01. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 872.431. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 1 of parameter k1__k2__length_scale is close to the specified upper bound 102.94099999999999. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 3 of parameter k1__k2__length_scale is close to the specified upper bound 84.609. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 4 of parameter k1__k2__length_scale is close to the specified upper bound 421.554. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 5 of parameter k1__k2__length_scale is close to the specified upper bound 135.202. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 6 of parameter k1__k2__length_scale is close to the specified lower bound 0.217008. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 7 of parameter k1__k2__length_scale is close to the specified upper bound 13.710999999999999. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 8 of parameter k1__k2__length_scale is close to the specified upper bound 245.97199999999998. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 11 of parameter k1__k2__length_scale is close to the specified upper bound 15.152. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 12 of parameter k1__k2__length_scale is close to the specified upper bound 16.468. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 13 of parameter k1__k2__length_scale is close to the specified upper bound 9.952. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 16 of parameter k1__k2__length_scale is close to the specified upper bound 2.8340000000000005. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 4 of parameter k1__k2__length_scale is close to the specified upper bound 421.554. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 7 of parameter k1__k2__length_scale is close to the specified upper bound 13.710999999999999. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 12 of parameter k1__k2__length_scale is close to the specified upper bound 16.468. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 13 of parameter k1__k2__length_scale is close to the specified upper bound 9.952. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 15 of parameter k1__k2__length_scale is close to the specified upper bound 549.137. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified lower bound 3.4897240000000007. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 1 of parameter k1__k2__length_scale is close to the specified lower bound 0.411764. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 7 of parameter k1__k2__length_scale is close to the specified lower bound 0.054844. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 8 of parameter k1__k2__length_scale is close to the specified upper bound 245.97199999999998. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 9 of parameter k1__k2__length_scale is close to the specified lower bound 1.116384. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 10 of parameter k1__k2__length_scale is close to the specified upper bound 17.086000000000002. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 11 of parameter k1__k2__length_scale is close to the specified upper bound 15.152. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 14 of parameter k1__k2__length_scale is close to the specified lower bound 0.56022. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 15 of parameter k1__k2__length_scale is close to the specified upper bound 549.137. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 16 of parameter k1__k2__length_scale is close to the specified upper bound 2.8340000000000005. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "2024-09-06 14:17:43 - PCGP_scikit - INFO - GP 0 score : 0.9552706589610446\n",
      "2024-09-06 14:17:43 - PCGP_scikit - INFO - GP 1 score : 0.8651365452599868\n",
      "2024-09-06 14:17:43 - PCGP_scikit - INFO - GP 2 score : 0.8763665551580173\n",
      "2024-09-06 14:17:43 - PCGP_scikit - INFO - GP 3 score : 0.37207779030865606\n",
      "2024-09-06 14:17:43 - __main__ - INFO - Emulator 'PCGP_scikit' trained and saved.\n",
      "\n",
      "2024-09-06 14:17:46 - __main__ - INFO - Emulator 'PCSK' trained and saved.\n",
      "\n",
      "2024-09-06 14:17:46 - AKSGP - INFO - Automatic kernel selection opted. Best kernel for each output dimension will be selected from the list of kernels:\n",
      "   ['Matern12', 'Matern32', 'Matern52', 'RBF']\n",
      "\n",
      "2024-09-06 14:17:46 - AKSGP - INFO - Shape of training arrays: (90, 17), (90, 4), (90, 4)\n",
      "2024-09-06 14:17:46 - AKSGP - INFO - Shape of validation arrays: (10, 17), (10, 4), (10, 4)\n",
      "2024-09-06 14:17:46 - AKSGP - INFO - Training GPs with all available kernels...\n",
      "2024-09-06 14:17:46 - AKSGP - INFO -   Standardizing input space...\n",
      "2024-09-06 14:17:46 - AKSGP - INFO -   Standardizing data...\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 4 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 5 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 7 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 8 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 13 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 14 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 15 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 16 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 4 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 7 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 13 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 16 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 6 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 7 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 8 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 13 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 16 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 6 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 7 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 13 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 16 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "2024-09-06 14:17:47 - AKSGP - INFO -   Trained GPs with Matern12 kernels.\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 6 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 7 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 8 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 16 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 7 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 16 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 4 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 5 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 7 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 14 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 16 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "2024-09-06 14:17:48 - AKSGP - INFO -   Trained GPs with Matern32 kernels.\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 7 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 16 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 4 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 8 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 16 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "2024-09-06 14:17:48 - AKSGP - INFO -   Trained GPs with Matern52 kernels.\n",
      "2024-09-06 14:17:48 - AKSGP - INFO -   Trained GPs with RBF kernels.\n",
      "2024-09-06 14:17:48 - AKSGP - INFO - Finding best kernels for each output dimension...\n",
      "2024-09-06 14:17:48 - AKSGP - INFO -   Selected best kernels for each output dimension:\n",
      "   ['Matern52', 'Matern32', 'Matern32', 'Matern32']\n",
      "\n",
      "2024-09-06 14:17:48 - AKSGP - INFO - Retraining the GPs with selected best kernels using all training data...\n",
      "2024-09-06 14:17:48 - AKSGP - INFO -   Standardizing input space...\n",
      "2024-09-06 14:17:48 - AKSGP - INFO -   Standardizing data...\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 5 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 7 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 14 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 4 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 8 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 16 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 7 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 16 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 7 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 8 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/jaiswal/miniconda3/envs/jssims_new/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 16 of parameter k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "2024-09-06 14:17:49 - AKSGP - INFO - Retraining GPs complete.\n",
      "\n",
      "2024-09-06 14:17:49 - AKSGP - INFO - Kernel after GP training for output dimension 0:\n",
      "3.06**2 * Matern(length_scale=[9.57, 35.1, 41.5, 25.9, 1e+03, 11.9, 24, 17.2, 1e+03, 8.97, 19.5, 29.6, 30.7, 11.2, 59.9, 33.5, 1e+03], nu=2.5)\n",
      "  Log-marginal-likelihood: -1.4620911362341218\n",
      "\n",
      "2024-09-06 14:17:49 - AKSGP - INFO - Kernel after GP training for output dimension 1:\n",
      "2.17**2 * Matern(length_scale=[8.8, 9.66, 44.3, 16.4, 55.2, 25.8, 62.2, 1e+03, 23.2, 11.4, 9.48, 18.7, 25.3, 143, 53.1, 27.4, 1e+03], nu=1.5)\n",
      "  Log-marginal-likelihood: -26.300032005000148\n",
      "\n",
      "2024-09-06 14:17:49 - AKSGP - INFO - Kernel after GP training for output dimension 2:\n",
      "2.32**2 * Matern(length_scale=[10.2, 6.92, 31.9, 16, 69.4, 25, 76, 1e+03, 1e+03, 12.4, 10.1, 19.8, 30.3, 33.4, 76.8, 24.3, 1e+03], nu=1.5)\n",
      "  Log-marginal-likelihood: -32.490951126147934\n",
      "\n",
      "2024-09-06 14:17:49 - AKSGP - INFO - Kernel after GP training for output dimension 3:\n",
      "2.73**2 * Matern(length_scale=[11.4, 6.57, 40.7, 13.1, 277, 1e+03, 26.7, 1e+03, 308, 18.2, 9.33, 28.3, 41.5, 25, 1e+03, 27, 95.4], nu=1.5)\n",
      "  Log-marginal-likelihood: -37.8354483750331\n",
      "\n",
      "2024-09-06 14:17:49 - __main__ - INFO - Emulator 'AKSGP' trained and saved.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to train and save emulators. \n",
    "\n",
    "methods = ['PCGP', 'PCGP_scikit', 'PCSK', 'AKSGP']  # specify only the emulators you want to train\n",
    "\n",
    "emus = {}\n",
    "for method in methods:\n",
    "\n",
    "    if method == 'PCGP':\n",
    "        prior = {'min': np.min(Ymean.T), 'max': np.max(Ymean.T)}\n",
    "        args = {'prior': prior}\n",
    "        emus[method] = emulator(x=xloc, theta=X, f=Ymean.T, method=method, args=args)\n",
    "        \n",
    "    elif method == 'PCSK':\n",
    "        args = {'simsd': Ystd.T}\n",
    "        emus[method] = emulator(x=xloc, theta=X, f=Ymean.T, method=method, args=args)\n",
    "        \n",
    "    elif method == 'AKSGP':\n",
    "        emus[method] = emulator_AKSGP(X=X, Y_mean=Ymean, Y_std=Ystd)\n",
    "        emus[method].fit(kernel='AKS', nrestarts=10, seed=None)\n",
    "        \n",
    "    elif method == 'PCGP_scikit':\n",
    "        emus[method] = PCGP_scikit(X=X, Y=Ymean, npc = 10)\n",
    "        emus[method].fit(nrestarts=10)\n",
    "        \n",
    "    else:\n",
    "        logger.error(f\"Unknown method '{method}'.\\n\")\n",
    "        continue\n",
    "        \n",
    "    # Saving the emulators after training\n",
    "    try:\n",
    "        filename = f'emulator_{method}.dill.gz'\n",
    "        with gzip.open(filename, 'wb') as f:\n",
    "            dill.dump(emus[method], f)\n",
    "        logger.info(f\"Emulator '{method}' trained and saved.\\n\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save emulator '{method}': {e}\\n\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved emulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emulators = {}\n",
    "for method in ['PCGP', 'PCSK', 'AKSGP', 'PCGP_scikit']:\n",
    "    filename = f'emulator_{method}.dill.gz'\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        emulators[method] = dill.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 14:16:14 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cpu time AKSGP: 9.17000000000553\n",
      "Training wall-clock time AKSGP: 2.563896894454956\n",
      "\n",
      "Prediction cpu time AKSGP: 0.0\n",
      "Prediction wall-clock time AKSGP: 0.001956939697265625\n",
      "\n",
      "Training cpu time PCGP_scikit: 6.930000000000291\n",
      "Training wall-clock time PCGP_scikit: 1.5556249618530273\n",
      "\n",
      "Prediction cpu time PCGP_scikit: 0.0\n",
      "Prediction wall-clock time PCGP_scikit: 0.0017108917236328125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from metrics import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load testing data\n",
    "test_dir = 'simulation_data/Pb_Pb_2760_Grad/test'\n",
    "\n",
    "X_test = np.loadtxt(os.path.join(test_dir, 'X.txt'))\n",
    "Ymean_test = np.loadtxt(os.path.join(test_dir, 'Ymean.txt'))\n",
    "Ystd_test = np.loadtxt(os.path.join(test_dir, 'Ystd.txt'))\n",
    "\n",
    "\n",
    "Ymean_test = Ymean_test[:numdesignpt,:numobs]\n",
    "Ystd_test = Ystd_test[:numdesignpt,:numobs]\n",
    "\n",
    "def metrics_cal(means1, var1, means2, var2):\n",
    "    # Initialize array's to store the distances\n",
    "    kl_div = np.zeros(means1.shape)\n",
    "    wasserstein_dist = np.zeros(means1.shape)\n",
    "    hellinger_dist = np.zeros(means1.shape)\n",
    "    \n",
    "    # Loop over each pair of means and variances\n",
    "    for i in range(means1.shape[0]):\n",
    "        for j in range(means1.shape[1]):\n",
    "            mu1 = means1[i, j]\n",
    "            mu2 = means2[i, j]\n",
    "            var1_ij = var1[i, j]\n",
    "            var2_ij = var2[i, j]\n",
    "            \n",
    "            # Calculate the distances for the current pair\n",
    "            kl_div[i, j] = kl_divergence_gaussian(mu1=mu1, Cov1=var1_ij, mu2=mu2, Cov2=var2_ij)\n",
    "            hellinger_dist[i, j] = hellinger_distance_gaussian(mu1=mu1, Cov1=var1_ij, mu2=mu2, Cov2=var2_ij)\n",
    "            wasserstein_dist[i, j] = wasserstein_distance_gaussian(mu1=mu1, Cov1=var1_ij, mu2=mu2, Cov2=var2_ij)\n",
    "\n",
    "    return kl_div, hellinger_dist, wasserstein_dist\n",
    "\n",
    "\n",
    "scaler_Y = StandardScaler()\n",
    "Ymean_test = scaler_Y.fit_transform(Ymean_test)\n",
    "Ystd_test = Ystd_test / scaler_Y.scale_\n",
    "\n",
    "\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "for method, emu in emulators.items():\n",
    "    # print(method)\n",
    "    \n",
    "    if method in {'PCGP', 'PCSK'}:\n",
    "        pred = emu.predict(x=xloc, theta=X_test)\n",
    "        predmean = pred.mean().T\n",
    "        predvar = pred.var().T\n",
    "        \n",
    "        predmean = scaler_Y.transform(predmean)\n",
    "        predvar = np.square(np.sqrt(predvar)/scaler_Y.scale_)\n",
    "\n",
    "        print(f\"Training cpu time {method}: {emu.traintotalcputime}\")\n",
    "        print(f\"Training wall-clock time {method}: {emu.trainwallclocktime}\\n\")\n",
    "        print(f\"Prediction cpu time {method}: {emu.predicttotalcputime}\")\n",
    "        print(f\"Prediction wall-clock time {method}: {emu.predictwallclocktime}\\n\")\n",
    "        \n",
    "        \n",
    "    elif method in {'AKSGP', 'PCGP_scikit'}:\n",
    "        predmean, predstd = emu.predict(X_test)\n",
    "        predvar = np.square(predstd)\n",
    "\n",
    "        predmean = scaler_Y.transform(predmean)\n",
    "        predvar = np.square(np.sqrt(predvar)/scaler_Y.scale_)\n",
    "\n",
    "        print(f\"Training cpu time {method}: {emu.traintotalcputime}\")\n",
    "        print(f\"Training wall-clock time {method}: {emu.trainwallclocktime}\\n\")\n",
    "        print(f\"Prediction cpu time {method}: {emu.predicttotalcputime}\")\n",
    "        print(f\"Prediction wall-clock time {method}: {emu.predictwallclocktime}\\n\")\n",
    "    \n",
    "    Yvar_test = np.square(Ystd_test)\n",
    "    \n",
    "    EC = intervalstats(Ymean_test, predmean, predvar)\n",
    "    RMSE = rmse(Ymean_test, predmean)\n",
    "    NRMSE = normalized_rmse(Ymean_test, predmean)\n",
    "    KLdiv, HD, WD = metrics_cal(predmean, predvar, Ymean_test, Yvar_test)\n",
    "\n",
    "    # Store the results in the list\n",
    "    results.append({\n",
    "        'Method': method,\n",
    "        'Empirical Coverage': ', '.join(['{:.6f}'.format(val) for val in EC]),\n",
    "        'RMSE': '{:.6f}'.format(RMSE),\n",
    "        'NRMSE': '{:.6f}'.format(NRMSE),\n",
    "        'KL Divergence': '{:.6f}'.format(np.mean(KLdiv)),\n",
    "        'Hellinger Distance': '{:.6f}'.format(np.mean(HD)),\n",
    "        'Wasserstein Distance': '{:.6f}'.format(np.mean(WD))\n",
    "    })\n",
    "\n",
    "# Convert the list of results into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method       Empirical Coverage          RMSE           NRMSE        KL Divergence   Hellinger Distance   Wasserstein Distance\n",
      "------------------------------------------------------------------------------------------------------------------------------\n",
      "PCGP         0.887977, 0.829358        0.278953        0.060936        29.258718         0.622252             0.266622            \n",
      "PCSK         0.876442, 0.852003        0.292602        0.063949        32.442426         0.631018             0.280686            \n",
      "AKSGP        0.847410, 0.704204        0.272827        0.059591        24.122800         0.621285             0.254739            \n",
      "PCGP_scikit  0.972239, 1.452532        0.298755        0.065328        67.216975         0.668979             0.386162            \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Format and print the header\n",
    "header = f\"{'Method':<12} {'Empirical Coverage':<27} {'RMSE':<14} {'NRMSE':<12} {'KL Divergence':<15} {'Hellinger Distance':<20} {'Wasserstein Distance':<20}\"\n",
    "print(header)\n",
    "print('-' * len(header))\n",
    "\n",
    "# Format and print each row\n",
    "for index, row in results_df.iterrows():\n",
    "    print(f\"{row['Method']:<12} {row['Empirical Coverage']:<25} {row['RMSE']:<15} {row['NRMSE']:<15} {row['KL Divergence']:<17} {row['Hellinger Distance']:<20} {row['Wasserstein Distance']:<20}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
